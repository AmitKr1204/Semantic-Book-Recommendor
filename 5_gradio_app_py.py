# -*- coding: utf-8 -*-
"""5_gradio_app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r2PRvfjVCHvZLDh0Qza0q0ETMS8dsdtx
"""

import pandas as pd

!pip install python-dotenv
import numpy as np
from dotenv import load_dotenv # Changed 'load_dtenv' to 'load_dotenv'

!pip install langchain-community
from langchain_community.document_loaders import TextLoader

!pip install langchain
from langchain.embeddings.openai import OpenAIEmbeddings # Changed import statement

!pip install chromadb  # Install the Chroma package, which is now named 'chromadb'
from langchain.vectorstores import Chroma # Import Chroma from langchain.vectorstores
from langchain.text_splitter import CharacterTextSplitter
#from langchain_chroma import Chroma

!pip install gradio
import gradio as gr

from langchain.embeddings import HuggingFaceEmbeddings

embedding = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings

embedding = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Assuming 'books_with_emotions.csv' contains the text data
loader = TextLoader('/content/books_with_emotions.csv')  # Replace with your file path
raw_documents = loader.load()
text_splitter = CharacterTextSplitter(separator='\n', chunk_size=1000, chunk_overlap=0) # Adjust chunk_size and overlap as needed
documents = text_splitter.split_documents(raw_documents)

db_books = Chroma.from_documents(documents, embedding=embedding)

!pip install -q sentence-transformers

from sentence_transformers import SentenceTransformer, util
import pandas as pd

# Load model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Load your book dataset
# Assuming 'books_with_emotions.csv' is your dataset
books = pd.read_csv("/content/books_with_emotions.csv")

# Encode book titles or summaries
book_texts = books['title'].tolist()  # or use 'description'
book_embeddings = model.encode(book_texts, convert_to_tensor=True)

# Encode query
query = "mystery with suspense"
query_embedding = model.encode(query, convert_to_tensor=True)

# Semantic search
scores = util.pytorch_cos_sim(query_embedding, book_embeddings)[0]
top_results = scores.argsort(descending=True)[:10]

# Show top recommended books
# Show top recommended books
books.iloc[top_results.cpu().numpy()] # Convert tensor to NumPy array on CPU

!pip install faiss-cpu -q

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# Generate embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(book_texts)

# Build FAISS index
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))

# Search
D, I = index.search(np.array([model.encode("sci-fi adventures")]), k=5)
# Show top recommended books
books.iloc[top_results.cpu().numpy()] # Convert tensor to NumPy array on CPU

!pip install -q sentence-transformers faiss-cpu gradio pandas numpy

import pandas as pd
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import gradio as gr

# Load your book dataset
books = pd.read_csv("/content/books_with_emotions.csv")
books["large_thumbnail"] = books["thumbnail"].fillna("") + "&fife800"
books["large_thumbnail"] = np.where(
    books["large_thumbnail"].isna() | books["large_thumbnail"].str.strip().eq(""),
    "download.jpeg",
    books["large_thumbnail"]
)

# Prepare sentence embeddings for book titles
model = SentenceTransformer('all-MiniLM-L6-v2')
book_texts = books['title'].fillna("").tolist()
book_embeddings = model.encode(book_texts, show_progress_bar=True)

# Build FAISS index
dimension = book_embeddings[0].shape[0]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(book_embeddings))

# Semantic search + emotion/tone filter
def retrieve_semantic_recommendations(query, category="All", tone=None, initial_top_k=50, final_top_k=16):
    query_embedding = model.encode([query])
    D, I = index.search(np.array(query_embedding), k=initial_top_k)
    recs = books.iloc[I[0]].copy()

    if category != "All":
        recs = recs[recs["simple_categories"] == category]

    if tone == "Happy":
        recs = recs.sort_values(by="happy", ascending=False)
    elif tone == "Surprising":
        recs = recs.sort_values(by="surprise", ascending=False)
    elif tone == "Sad":
        recs = recs.sort_values(by="sad", ascending=False)
    elif tone == "Angry":
        recs = recs.sort_values(by="angry", ascending=False)
    elif tone == "Suspenseful":
        recs = recs.sort_values(by="suspenseful", ascending=False)

    return recs.head(final_top_k)

# Recommendation formatting for display
def recommend_books(query, category="All", tone="Happy"):
    recommendations = retrieve_semantic_recommendations(query, category, tone)
    results = []

    for _, row in recommendations.iterrows():
        description = row.get("description", "")
        truncated_description = " ".join(description.split()[:30]) + "..."

        authors_split = row.get('authors', '').split(";")
        if len(authors_split) > 2:
            authors_str = f"{', '.join(authors_split[:-1])}, and {authors_split[-1]}"
        else:
            authors_str = ", ".join(authors_split)

        caption = f"{row['title']} by {authors_str}: {truncated_description}"
        results.append((row["large_thumbnail"], caption))

    return results

# Gradio UI
categories = ["All"] + sorted(books["simple_categories"].dropna().unique().tolist())
tones = ["None", "Happy", "Surprising", "Angry", "Suspenseful", "Sad"]

with gr.Blocks(theme=gr.themes.Base()) as dashboard:
    gr.Markdown("# ðŸ“š Semantic Book Recommender")

    with gr.Row():
        query = gr.Textbox(label="Enter a description of the book you want", placeholder="e.g., A story about love and redemption")
        category = gr.Dropdown(choices=categories, label="Select category", value="All")
        tone = gr.Dropdown(choices=tones, label="Select emotional tone", value="None")

    output = gr.Gallery(label="Recommended Books")

    btn = gr.Button("Recommend Books")
    btn.click(fn=recommend_books, inputs=[query, category, tone], outputs=output)

dashboard.launch()

